[2016-12-13 18:58:50,209] INFO Bootstrapping AmbryServer (com.github.ambry.server.AmbryMain)
[2016-12-13 18:58:50,220] INFO According to InetAddress.getLocalHost.getHostName we are himrod-8 (com.github.ambry.metrics.JmxServer)
[2016-12-13 18:58:50,520] INFO Started jmx serverJmxServer port= 55215 url= service:jmx:rmi:///jndi/rmi://himrod-8:55215/jmxrmi (com.github.ambry.metrics.JmxServer)
[2016-12-13 18:58:50,529] INFO starting (com.github.ambry.server.AmbryServer)
[2016-12-13 18:58:50,529] INFO Setting up JMX. (com.github.ambry.server.AmbryServer)
[2016-12-13 18:58:50,597] INFO creating configs (com.github.ambry.server.AmbryServer)
[2016-12-13 18:58:50,604] INFO Verifying properties (com.github.ambry.config.VerifiableProperties)
[2016-12-13 18:58:50,607] INFO Property host.name is overridden to localhost (com.github.ambry.config.VerifiableProperties)
[2016-12-13 18:58:50,607] INFO Property store.compaction.hotness.threshold is overridden to 10 (com.github.ambry.config.VerifiableProperties)
[2016-12-13 18:58:50,607] INFO Property store.compaction.threshold is overridden to 0.5 (com.github.ambry.config.VerifiableProperties)
[2016-12-13 18:58:50,609] INFO check if node exist in clustermap host localhost port 6667 (com.github.ambry.server.AmbryServer)
[2016-12-13 18:58:50,619] INFO Starting store manager (com.github.ambry.store.StoreManager)
[2016-12-13 18:58:50,980] INFO Index : /localdisk2/h26tan/2 log end offset of index  before recovery 0 (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:50,980] INFO Index : /localdisk2/h26tan/2 performing recovery on index with start offset 0 and end offset 0 (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:50,982] INFO Index : /localdisk2/h26tan/2 Starting hard delete recovery (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:50,983] INFO Index : /localdisk2/h26tan/2 Finished performing hard delete recovery (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:51,315] INFO Index : /localdisk0/h26tan/0 log end offset of index  before recovery 0 (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:51,315] INFO Index : /localdisk0/h26tan/0 performing recovery on index with start offset 0 and end offset 0 (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:51,315] INFO Index : /localdisk0/h26tan/0 Starting hard delete recovery (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:51,316] INFO Index : /localdisk0/h26tan/0 Finished performing hard delete recovery (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:51,636] INFO Index : /localdisk1/h26tan/1 log end offset of index  before recovery 0 (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:51,636] INFO Index : /localdisk1/h26tan/1 performing recovery on index with start offset 0 and end offset 0 (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:51,636] INFO Index : /localdisk1/h26tan/1 Starting hard delete recovery (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:51,636] INFO Index : /localdisk1/h26tan/1 Finished performing hard delete recovery (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:51,638] INFO Starting store manager complete (com.github.ambry.store.StoreManager)
[2016-12-13 18:58:51,644] INFO BlockingChannelConnectionPool started (com.github.ambry.network.BlockingChannelConnectionPool)
[2016-12-13 18:58:51,666] INFO Reading replica tokens for mount path /localdisk2/h26tan (com.github.ambry.replication.ReplicationManager)
[2016-12-13 18:58:51,666] INFO Reading replica tokens for mount path /localdisk0/h26tan (com.github.ambry.replication.ReplicationManager)
[2016-12-13 18:58:51,666] INFO Reading replica tokens for mount path /localdisk1/h26tan (com.github.ambry.replication.ReplicationManager)
[2016-12-13 18:58:51,666] WARN Number of Datacenters to replicate from is 0, not starting any replica threads (com.github.ambry.replication.ReplicationManager)
[2016-12-13 18:58:51,705] INFO Starting 8 processor threads (com.github.ambry.network.SocketServer)
[2016-12-13 18:58:51,718] INFO Starting acceptor threads (com.github.ambry.network.SocketServer)
[2016-12-13 18:58:51,724] INFO Awaiting socket connections on localhost:6667 (com.github.ambry.network.Acceptor)
[2016-12-13 18:58:51,725] INFO Started server (com.github.ambry.network.SocketServer)
[2016-12-13 18:58:51,725] INFO started (com.github.ambry.server.AmbryServer)
[2016-12-13 18:58:51,725] INFO Server startup time in Ms 1196 (com.github.ambry.server.AmbryServer)
[2016-12-13 18:58:55,559] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:58:55,563] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:58:55,564] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:58:58,148] INFO Creating first segment (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:58,172] INFO Creating first segment (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:58:58,487] INFO Creating first segment (com.github.ambry.store.PersistentIndex)
[2016-12-13 18:59:00,541] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:00,542] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:00,543] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:05,539] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:05,540] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:05,541] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:10,538] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:10,539] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:10,539] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:15,537] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:15,538] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:15,538] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:20,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:20,532] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:20,532] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:25,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:25,532] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:25,532] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:30,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:30,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:30,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:35,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:35,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:35,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:45,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:45,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:45,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:45,770] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:46,340] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[2]: Compaction runtime: 569ms
[2016-12-13 18:59:46,341] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@7b3fce4d (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk2/h26tan/2
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 18:59:46,341] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@3158a9f (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk2/h26tan/2
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:49,623] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
[2016-12-13 18:59:50,023] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[1]: Compaction runtime: 400ms
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:50,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:50,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:50,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:55,092] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:55,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:55,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 18:59:55,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 18:59:55,903] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Compaction runtime: 811ms
[2016-12-13 18:59:55,904] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAAAAAAAJDEwMzY4YTM5LTAyNzUtNDE1Ny04NWJhLWNlMmEzNTNkMzBjZQ, ClientId=localhost, CorrelationId=5508] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 18:59:55,904] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@3fafe567 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 18:59:55,904] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAAAAAAAJDMyYTAwOTA5LWUzMWYtNDM0OS04NDBjLWY3ZmFmMjYyZTE2NQ, ClientId=localhost, CorrelationId=5448] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 18:59:55,904] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAAAAAAAJDZlMGQ4M2YwLWY4MGMtNDg3My05NGYyLWEzMzQzMGYxMmI2Nw, ClientId=localhost, CorrelationId=5484] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 18:59:55,904] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@4c509a05 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:00,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:00,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:00,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:05,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:05,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:05,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:10,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:10,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:10,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:15,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:15,532] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:15,533] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:20,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:20,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:20,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:25,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:25,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:25,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:25,580] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:25,918] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[2]: Compaction runtime: 338ms
[2016-12-13 19:00:25,918] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@62dfb098 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk2/h26tan/2
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:00:25,918] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@4bc2fdde (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk2/h26tan/2
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:30,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:30,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:30,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:34,260] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:34,701] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[1]: Compaction runtime: 441ms
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:34,702] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAABAAAAJDg2N2Y5MmFkLWExYzAtNDJiNS05ZjIyLTZiODYzYmQ0ZmM3ZA, ClientId=localhost, CorrelationId=9151] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 19:00:34,702] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@461137c6 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:35,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:35,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:35,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:38,633] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
[2016-12-13 19:00:39,100] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Compaction runtime: 467ms
[2016-12-13 19:00:39,100] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAAAAAAAJGEyZGJhYzFjLTNlYmMtNGIwOS1iNzgzLTEwOTk5OTdjZDlkZQ, ClientId=localhost, CorrelationId=9560] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 19:00:39,100] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@271d900d (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:00:39,100] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@76d53356 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:45,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:45,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:45,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:50,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:50,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:50,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:00:55,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:55,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:00:55,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:00,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:00,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:00,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:05,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:05,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:05,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:07,064] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:07,306] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[2]: Compaction runtime: 242ms
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:10,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:10,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:10,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:15,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:15,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:15,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:17,620] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:17,994] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[1]: Compaction runtime: 374ms
[2016-12-13 19:01:17,994] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@16b50694 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:01:17,994] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAABAAAAJGY5NzJmOGYwLWYyNWYtNDM2YS04ZDRkLTQ4NTE5MjRmMzQyMg, ClientId=localhost, CorrelationId=13102] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 19:01:17,994] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAABAAAAJGM1ZDA3YWQ3LTQ4NjEtNDU1OC1hYzg5LWRmMzAzMDVmYzIwOA, ClientId=localhost, CorrelationId=13103] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:20,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:20,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:20,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:25,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:25,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:25,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:25,936] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:26,769] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Compaction runtime: 833ms
[2016-12-13 19:01:26,769] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@1f5a0bbc (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:01:26,769] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAAAAAAAJDZhODkxZmQyLTNlOWYtNGYyNC1hODRmLTFkNzM5OGJmNWNmYg, ClientId=localhost, CorrelationId=13866] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 19:01:26,769] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAAAAAAAJDU0MjU5NDJkLTNmMzItNGMzZS04MzZmLWRlYWJkMzZkOGY3Mg, ClientId=localhost, CorrelationId=13869] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 19:01:26,769] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@50b873b8 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:01:26,769] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@7db55e6e (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:30,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:30,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:30,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:35,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:35,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:35,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:45,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:45,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:45,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:50,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:50,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:50,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:54,864] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:55,046] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[2]: Compaction runtime: 182ms
[2016-12-13 19:01:55,046] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@19163ae3 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk2/h26tan/2
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:01:55,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:55,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:01:55,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:00,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:00,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:00,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:01,136] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:01,433] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[1]: Compaction runtime: 297ms
[2016-12-13 19:02:01,433] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@aa711 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:02:01,433] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAABAAAAJDkwZjBmMTk5LWQ5OWMtNGY1OC04ZmVhLTBhMjFiYWYyMzRkNA, ClientId=localhost, CorrelationId=17077] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 19:02:01,433] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@3b5e4d1c (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:02:01,433] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@2c1887b7 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:05,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:05,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:05,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:10,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:10,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:10,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:14,715] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:15,239] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Compaction runtime: 523ms
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:15,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:15,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:15,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:20,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:20,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:20,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:25,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:25,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:25,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:30,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:30,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:30,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:35,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:35,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:35,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:40,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:40,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:40,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:45,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:45,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:45,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:46,231] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:46,392] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[2]: Compaction runtime: 161ms
[2016-12-13 19:02:46,393] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAACAAAAJGE0MDRlYjZkLWNlZmMtNDVmMi05N2VkLWJhYzBkODY1ZmI4NA, ClientId=localhost, CorrelationId=21078] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk2/h26tan/2
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 19:02:46,393] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@5699b665 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk2/h26tan/2
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:50,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:50,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:50,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:53,962] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:54,294] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[1]: Compaction runtime: 332ms
[2016-12-13 19:02:54,294] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@2f37e8bc (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:02:54,294] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@18a91dd9 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:02:54,294] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@18d4479b (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:02:54,294] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAABAAAAJDAzYmJlMjE1LTA5MTUtNGZiYi1hNjhlLWQzOTI2NzMyNTg4Nw, ClientId=localhost, CorrelationId=21781] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
[2016-12-13 19:02:54,294] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@7f90a6db (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk1/h26tan/1
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:02:55,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:55,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:02:55,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:00,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:00,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:00,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:01,681] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:02,095] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[0]: Compaction runtime: 414ms
[2016-12-13 19:03:02,096] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@4d4a74b1 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:03:02,096] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@6a47808b (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:03:02,096] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@f719660 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:03:02,096] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@5333381b (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:03:02,096] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@47a89f49 (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk0/h26tan/0
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:05,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:05,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:05,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:10,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:10,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:10,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:15,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:15,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:15,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:20,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:20,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:20,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:25,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:25,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:25,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[2]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:30,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:30,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:30,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:35,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:35,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:35,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:40,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:40,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:45,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:45,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:45,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:50,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:50,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:50,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:55,529] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:55,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:03:55,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:03:59,725] INFO Store : BEGIN COMPACTION (com.github.ambry.store.BlobStore)
[2016-12-13 19:04:00,166] INFO Store : END COMPACTION (com.github.ambry.store.BlobStore)
Store Partition[2]: Compaction runtime: 441ms
[2016-12-13 19:04:00,167] ERROR Store exception on a put with error code Unknown_Error for request com.github.ambry.protocol.PutRequest$ReceivedPutRequest@4023cecd (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to put blobs to store /localdisk2/h26tan/2
	at com.github.ambry.store.BlobStore.put(BlobStore.java:220)
	at com.github.ambry.server.AmbryRequests.handlePutRequest(AmbryRequests.java:168)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:121)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.put(BlobStore.java:193)
	... 4 more
[2016-12-13 19:04:00,167] ERROR Store exception on a delete with error code Unknown_Error for request DeleteRequest[BlobID=AAEAAQAAAAAAAAACAAAAJDE1MDAxZWMzLWE3ZmMtNDMyNC04YTExLWIyM2JiMzAwMGYxYQ, ClientId=localhost, CorrelationId=25323] (com.github.ambry.server.AmbryRequests)
com.github.ambry.store.StoreException: Unknown error while trying to delete blobs from store /localdisk2/h26tan/2
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:289)
	at com.github.ambry.server.AmbryRequests.handleDeleteRequest(AmbryRequests.java:364)
	at com.github.ambry.server.AmbryRequests.handleRequests(AmbryRequests.java:127)
	at com.github.ambry.server.RequestHandler.run(RequestHandler.java:46)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: File span needs to be positive
	at com.github.ambry.store.FileSpan.<init>(FileSpan.java:25)
	at com.github.ambry.store.BlobStore.delete(BlobStore.java:253)
	... 4 more
Store Partition[0]: Partition is Hot, Defer the compaction...
Store Partition[1]: Partition is Hot, Defer the compaction...
[2016-12-13 19:04:00,530] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk0/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:04:00,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk1/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-12-13 19:04:00,531] WARN Error writing to com.github.ambry.clustermap.ClusterMap.localhost-6667-/localdisk2/h26tan-ResourceState (com.codahale.metrics.CsvReporter)
java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createNewFile(File.java:1006)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:241)
	at com.codahale.metrics.CsvReporter.reportGauge(CsvReporter.java:234)
	at com.codahale.metrics.CsvReporter.report(CsvReporter.java:150)
	at com.codahale.metrics.ScheduledReporter.report(ScheduledReporter.java:116)
	at com.codahale.metrics.ScheduledReporter$1.run(ScheduledReporter.java:87)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Store Partition[1]: Partition is Hot, Defer the compaction...
Store Partition[0]: Partition is Hot, Defer the compaction...
